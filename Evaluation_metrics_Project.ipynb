{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOdUnjvG3AMA",
        "outputId": "e7dd305b-b4fd-4252-b0e7-1c1e5d22b66a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Prepare Data"
      ],
      "metadata": {
        "id": "28AVgKNB23E_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_RBYMWQZ2pnB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import namedtuple\n",
        "import math\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Book = namedtuple('Book', ['title', 'content', 'vector'])\n",
        "\n",
        "def load_books():\n",
        "    books_dir = \"/content/drive/MyDrive/BookRetrieval(IR)/Book Retrieval Project\"\n",
        "    books = []\n",
        "    for filename in os.listdir(books_dir):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(books_dir, filename)\n",
        "            try:\n",
        "                # First, try to read the file with UTF-8 encoding\n",
        "                with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                    content = file.read()\n",
        "            except UnicodeDecodeError:\n",
        "                # If UTF-8 fails, try with ISO-8859-1 encoding\n",
        "                with open(file_path, 'r', encoding='iso-8859-1') as file:\n",
        "                    content = file.read()\n",
        "            title = os.path.splitext(filename)[0]\n",
        "            books.append(Book(title=title, content=content, vector=None))\n",
        "    return books\n"
      ],
      "metadata": {
        "id": "bbdGiCGh3DW-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Space Model"
      ],
      "metadata": {
        "id": "_TIRIqZ13vwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_space_model(books):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    content_list = [book.content for book in books]\n",
        "    tfidf_matrix = vectorizer.fit_transform(content_list)\n",
        "\n",
        "    vectorized_books = []\n",
        "    for i, book in enumerate(books):\n",
        "        vector = tfidf_matrix[i].toarray()[0]\n",
        "        vectorized_books.append(Book(title=book.title, content=book.content, vector=vector))\n",
        "\n",
        "    return vectorizer, vectorized_books\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
        "    magnitude1 = math.sqrt(sum(a * a for a in vec1))\n",
        "    magnitude2 = math.sqrt(sum(b * b for b in vec2))\n",
        "    return dot_product / (magnitude1 * magnitude2)\n",
        "\n",
        "def search_books(query, vectorizer, books):\n",
        "    query_vector = vectorizer.transform([query]).toarray()[0]\n",
        "    results = []\n",
        "    for book in books:\n",
        "        similarity = cosine_similarity(query_vector, book.vector)\n",
        "        results.append((book, similarity))\n",
        "    return sorted(results, key=lambda x: x[1], reverse=True)[:5]"
      ],
      "metadata": {
        "id": "3S37Nr5o3nWC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "lDEtX-d537iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "# Example ground truth\n",
        "ground_truth = {\n",
        "    'python': ['Flask Web Development Developing Web Applications With Python (Miguel Grinberg) (Z-Library)',\n",
        "               'Building The Data Lakehouse (Bill Inmon, Mary Levins, Ranjeet Srivastava) (Z-Library)',\n",
        "               'Fundamentals of Data Engineering Plan and Build Robust Data Systems (Joe Reis, Matt Housley) (Z-Library)',\n",
        "               'The Hundred-Page Machine Learning Book (Andriy Burkov) (Z-Library)',\n",
        "               'Designing Cloud Data Platforms (Danil Zburivsky, Lynda Partner) (Z-Library)'],\n",
        "    'cloud': ['Designing Cloud Data Platforms (Danil Zburivsky, Lynda Partner) (Z-Library)',\n",
        "              'Fundamentals of Data Engineering Plan and Build Robust Data Systems (Joe Reis, Matt Housley) (Z-Library)',\n",
        "              'Spring in Action (Craig Walls) (Z-Library)',\n",
        "              'Building The Data Lakehouse (Bill Inmon, Mary Levins, Ranjeet Srivastava) (Z-Library)',\n",
        "              'Continuous Delivery Reliable Software Releases Through Build, Test, and Deployment Automation (Humble, Jez Farley, David [Humble etc.) (Z-Library)'],\n",
        "}\n",
        "\n",
        "# Function to evaluate the search results\n",
        "def evaluate_search(queries, vectorizer, books, ground_truth):\n",
        "    for query in queries:\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        # Get relevant books for the query from ground truth\n",
        "        relevant_books = ground_truth.get(query, [])\n",
        "        results = search_books(query, vectorizer, books)\n",
        "        retrieved_books = [book.title for book, _ in results]\n",
        "\n",
        "        # Mark ground truth relevance (1 for relevant, 0 for non-relevant)\n",
        "        for book in books:\n",
        "            if book.title in relevant_books:\n",
        "                y_true.append(1)  # Book is relevant\n",
        "            else:\n",
        "                y_true.append(0)  # Book is not relevant\n",
        "\n",
        "            if book.title in retrieved_books:\n",
        "                y_pred.append(1)  # Book was retrieved by the search\n",
        "            else:\n",
        "                y_pred.append(0)  # Book was not retrieved\n",
        "\n",
        "        # Calculate precision, recall, and accuracy\n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        # Print metrics for the current query\n",
        "        print(f\"Query: '{query}'\")\n",
        "        print(f\"  Precision: {precision:.2f}\")\n",
        "        print(f\"  Recall: {recall:.2f}\")\n",
        "        print(f\"  Accuracy: {accuracy:.2f}\\n\")\n",
        "\n",
        "# Load books and vectorize them\n",
        "books = load_books()\n",
        "vectorizer, vectorized_books = create_vector_space_model(books)\n",
        "\n",
        "# Example query list for evaluation\n",
        "queries = ['python', 'cloud']\n",
        "# Run the evaluation\n",
        "evaluate_search(queries, vectorizer, vectorized_books, ground_truth)\n"
      ],
      "metadata": {
        "id": "MYaLu8bZ39bN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3755825-8110-42cc-d301-1be6fca2a025"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'python'\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  Accuracy: 1.00\n",
            "\n",
            "Query: 'cloud'\n",
            "  Precision: 0.80\n",
            "  Recall: 1.00\n",
            "  Accuracy: 0.95\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UdUvXyVd_bib"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}